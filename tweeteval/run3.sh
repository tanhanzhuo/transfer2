#CUDA_VISIBLE_DEVICES=3 python finetune_lrtune_fs_early.py --task_name eval-stance_clean,eval-emotion_clean,eval-irony_clean,eval-offensive_clean,eval-hate_clean,sem21-task7-humor_clean,sem22-task6-sarcasm_clean --learning_rate 1e-5 --shot full --model_name_or_path vinai/bertweet-base --results_name results_bertweet.txt --seed 0,1,2,3,4,5,6,7,8,9
#CUDA_VISIBLE_DEVICES=3 python finetune_lrtune_fs_early.py --task_name eval-stance_clean,eval-emotion_clean,eval-irony_clean,eval-offensive_clean,eval-hate_clean,sem21-task7-humor_clean,sem22-task6-sarcasm_clean --learning_rate 1e-5 --shot full --model_name_or_path ../pretrain/hashtag/hash_group_111_100/99999/ --results_name results_111_100-99999.txt --seed 0,1,2,3,4,5,6,7,8,9
#CUDA_VISIBLE_DEVICES=3 python finetune_lrtune_fs_early.py --task_name eval-stance_clean,eval-emotion_clean,eval-irony_clean,eval-offensive_clean,eval-hate_clean,sem21-task7-humor_clean,sem22-task6-sarcasm_clean --learning_rate 1e-5 --shot full --model_name_or_path ../pretrain/hashtag/hash_group_111_100/9999/ --results_name results_111_100-9999.txt --seed 0,1,2,3,4,5,6,7,8,9
#CUDA_VISIBLE_DEVICES=3 python finetune_lrtune_fs_early.py --task_name eval-stance_clean,eval-emotion_clean,eval-irony_clean,eval-offensive_clean,eval-hate_clean,sem21-task7-humor_clean,sem22-task6-sarcasm_clean --learning_rate 1e-5 --shot full --model_name_or_path ../pretrain/hashtag/hash_group_111_sep_100/99999/ --results_name results_111_sep_100-99999.txt --seed 0,1,2,3,4,5,6,7,8,9
#CUDA_VISIBLE_DEVICES=3 python finetune_lrtune_fs_early.py --task_name eval-stance_clean,eval-emotion_clean,eval-irony_clean,eval-offensive_clean,eval-hate_clean,sem21-task7-humor_clean,sem22-task6-sarcasm_clean --learning_rate 1e-5 --shot full --model_name_or_path ../pretrain/hashtag/hash_group_111_sep_100/9999/ --results_name results_111_sep_100-9999.txt --seed 0,1,2,3,4,5,6,7,8,9

#CUDA_VISIBLE_DEVICES=3 python finetune_lrtune_extend_position_tokentype_fs.py --task_name eval-stance_clean,eval-emotion_clean,eval-irony_clean,eval-offensive_clean,eval-hate_clean,sem21-task7-humor_clean,sem22-task6-sarcasm_clean --model_name_or_path vinai/bertweet-base --method hash_fuldata_bt_hashseg_top_1_rerank --results_name results_bt_rerank.txt --token_type 1 --learning_rate 1e-5 --shot full --weight 0 --seed 0,1,2,3,4,5,6,7,8,9
#CUDA_VISIBLE_DEVICES=3 python finetune_lrtune_extend_position_tokentype_fs.py --task_name eval-stance_clean,eval-emotion_clean,eval-irony_clean,eval-offensive_clean,eval-hate_clean,sem21-task7-humor_clean,sem22-task6-sarcasm_clean --model_name_or_path vinai/bertweet-base --method hash_fuldata_bt_hashseg_top_1 --results_name results_bt.txt --token_type 1 --learning_rate 1e-5 --shot full --weight 0 --seed 0,1,2,3,4,5,6,7,8,9

#CUDA_VISIBLE_DEVICES=1 python finetune_lrtune_extend_position_tokentype_fs.py --task_name eval-stance_clean,eval-emotion_clean,eval-irony_clean,eval-offensive_clean,eval-hate_clean,sem21-task7-humor_clean,sem22-task6-sarcasm_clean --model_name_or_path ../pretrain/hashtag/hash_group_111_100/99999/ --method hash_fuldata_bt_hashseg_top_1_rerank --results_name results_H111-100-99999_bt_rerank.txt --token_type 1 --learning_rate 1e-5 --shot full --weight 0 --seed 0,1,2,3,4,5,6,7,8,9
#CUDA_VISIBLE_DEVICES=1 python finetune_lrtune_extend_position_tokentype_fs.py --task_name eval-stance_clean,eval-emotion_clean,eval-irony_clean,eval-offensive_clean,eval-hate_clean,sem21-task7-humor_clean,sem22-task6-sarcasm_clean --model_name_or_path ../pretrain/hashtag/hash_group_111_100/99999/ --method hash_fuldata_bt_hashseg_top_1 --results_name results_H111-100-99999_bt.txt --token_type 1 --learning_rate 1e-5 --shot full --weight 0 --seed 0,1,2,3,4,5,6,7,8,9
#
#CUDA_VISIBLE_DEVICES=1 python finetune_lrtune_extend_position_tokentype_fs.py --task_name eval-stance_clean,eval-emotion_clean,eval-irony_clean,eval-offensive_clean,eval-hate_clean,sem21-task7-humor_clean,sem22-task6-sarcasm_clean --model_name_or_path ../pretrain/hashtag/hash_group_111_sep_100/99999/ --method hash_fuldata_bt_hashseg_top_1_rerank --results_name results_H111-sep-100-99999_bt_rerank.txt --token_type 1 --learning_rate 1e-5 --shot full --weight 0 --seed 0,1,2,3,4,5,6,7,8,9
#CUDA_VISIBLE_DEVICES=1 python finetune_lrtune_extend_position_tokentype_fs.py --task_name eval-stance_clean,eval-emotion_clean,eval-irony_clean,eval-offensive_clean,eval-hate_clean,sem21-task7-humor_clean,sem22-task6-sarcasm_clean --model_name_or_path ../pretrain/hashtag/hash_group_111_sep_100/99999/ --method hash_fuldata_bt_hashseg_top_1 --results_name results_H111-sep-100-99999_bt.txt --token_type 1 --learning_rate 1e-5 --shot full --weight 0 --seed 0,1,2,3,4,5,6,7,8,9

for epoch in 99999 199999
do
  CUDA_VISIBLE_DEVICES=7 python finetune_lrtune_extend_position_tokentype_fs.py --task_name eval-stance,eval-emotion,eval-irony,eval-offensive,eval-hate,sem21-task7-humor --model_name_or_path ../pretrain/hashtag/hash_group_111_rep0_100_5e5/${epoch}/ --method hash_fuldata_bt_hashseg_top_1 --results_name results_ft_fs_${epoch}5e5_retri.txt --max_seq_length 514 --token_type 1 --learning_rate 1e-5 --batch_size 16 --seed 0,1,2,3,4,5,6,7,8,9 --shot 16,32,64,128,256,512,full
  CUDA_VISIBLE_DEVICES=7 python finetune_lrtune_fs_early.py --task_name eval-stance,eval-emotion,eval-irony,eval-offensive,eval-hate,sem21-task7-humor --model_name_or_path ../pretrain/hashtag/hash_group_111_rep0_100_5e5/${epoch}/ --results_name results_ft_fs_${epoch}5e5.txt --learning_rate 1e-5 --batch_size 16 --seed 0,1,2,3,4,5,6,7,8,9 --shot 16,32,64,128,256,512,full
done

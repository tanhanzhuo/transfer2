import tweepy
from pagination import Paginator
import os
emo_100={'ğŸ˜ ': 39968, 'ğŸ—£': 41421, 'ğŸŒš': 42538, 'Â®': 43092, 'ğŸ˜¶': 43145, 'ğŸ™ğŸ¾': 43797, 'ğŸ‘‘': 44462, 'ğŸ˜–': 46428, 'ğŸ˜¥': 46615, 'âœŒï¸': 46644, 'â˜¹ï¸': 46909, 'ğŸ’š': 48557, 'Â©': 49189, 'ğŸ‘Š': 49252, 'ğŸ¥°': 49539, 'ğŸ’“': 55596, 'ğŸ™Š': 57845, 'ğŸ˜»': 59191, 'ğŸ“·': 60233, 'ğŸ’ª': 60579, 'âœ‹': 60885, 'ğŸ˜£': 60888, 'ğŸ‡ºğŸ‡¸': 61952, 'âœŒ': 63647, 'â€¼ï¸': 63962, 'ğŸ’˜': 64140, 'ğŸ˜‡': 64764, 'ğŸ˜›': 64790, 'ğŸ˜ƒ': 64805, 'ğŸ˜·': 66930, 'ğŸ˜“': 67046, 'ğŸ’›': 67355, 'ğŸ¤—': 71526, 'ğŸ™‚': 72717, 'ğŸ’': 72994, 'ğŸ˜': 73519, 'ğŸ’‹': 75210, 'ğŸ˜¬': 75830, 'ğŸ˜€': 76077, 'ğŸ˜†': 77151, 'ğŸ’': 98079, 'ğŸ‰': 100212, 'ğŸ˜±': 100653, 'ğŸ˜¤': 102889, 'ğŸ˜„': 105564, 'ğŸ’”': 106974, 'ğŸ˜ª': 107703, 'ğŸ˜¡': 111627, 'ğŸ’—': 115936, 'ğŸ˜«': 116199, 'ğŸ˜': 120496, 'ğŸ™ˆ': 121236, 'ğŸ˜ˆ': 122249, 'ğŸ˜œ': 122721, 'ğŸ’–': 127339, 'ğŸ’™': 132498, 'ğŸ˜‹': 136738, 'â˜º': 138523, 'ğŸ˜': 139500, 'ğŸ¥º': 141039, 'ğŸ¶': 144650, 'ğŸ’œ': 146993, 'ğŸ‘': 148373, 'ğŸ˜‘': 153020, 'ğŸ™ƒ': 153827, 'ğŸ˜•': 155966, 'ğŸ˜¢': 161518, 'ğŸ‘': 166034, 'ğŸ˜´': 170803, 'ğŸ¤£': 175802, 'âœ¨': 180694, 'ğŸ™Œ': 189629, 'ğŸ™': 194271, 'ğŸ˜': 195752, 'â˜ºï¸': 197675, 'ğŸ˜Œ': 213108, 'ğŸ˜‰': 213792, 'ğŸ˜…': 215726, 'ğŸ’€': 235897, 'ğŸ‘€': 251745, 'ğŸ¤”': 286776, 'ğŸ™„': 293981, 'ğŸ˜³': 294057, 'ğŸ‘Œ': 304936, 'ğŸ˜': 309821, 'ğŸ˜': 310541, 'ğŸ’¯': 317351, 'ğŸ”¥': 332628, 'ğŸ’•': 332689, 'ğŸ˜˜': 343735, 'ğŸ˜”': 353626, 'â¤': 360275, 'â™¥': 386672, 'ğŸ˜’': 511117, 'ğŸ˜Š': 612212, 'ğŸ˜©': 619148, 'â¤ï¸': 727927, 'ğŸ˜': 1015346, 'ğŸ˜­': 1302483, 'ğŸ˜‚': 4128538}
emo_list = list(emo_100.keys())
# consumer_key=os.environ.get("BEARER_TOKEN")
# consumer_secret=os.environ.get("BEARER_TOKEN")
# access_token=os.environ.get("BEARER_TOKEN")
# access_token_secret=os.environ.get("BEARER_TOKEN")
bearer_token = os.environ.get("BEARER_TOKEN")

client = tweepy.Client( bearer_token=bearer_token,
                        # consumer_key=consumer_key,
                        # consumer_secret=consumer_secret,
                        # access_token=access_token,
                        # access_token_secret=access_token_secret,
                        return_type=dict)

query_emo = ' ('+' OR '.join(emo_list[36:]) + ')'
query_txt = '-is:retweet -RT -has:links -has:media -has:videos -has:images lang:en (#irony OR #sarcasm OR #not)'

all_tweet = []
tweets = Paginator(client.search_recent_tweets, query=query_txt+query_emo,
                              #tweet_fields=['context_annotations', 'created_at'],
                              max_results=10).flatten()
for tweet in tweets:
    all_tweet.append(tweet)
import json
with open('retrieve_sem18-task3-irony.json', 'w', encoding='utf-8') as f:
    for tweet in all_tweet:
        json.dump(tweet, f)
        f.write('\n')